{"cells":[{"cell_type":"markdown","metadata":{"id":"iGwGCDmoSEPe"},"source":["# RNN/Transformer for Modeling Sentences\n","\n","In this task, we will use an RNN or a transformer model to model sentences. The task is to predict the next character in a sentence. "]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import sys\n","sys.path.append('/content/drive/MyDrive/cs137assignments/assignment4')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ey8OAYoHSSHs","executionInfo":{"status":"ok","timestamp":1669494385894,"user_tz":300,"elapsed":1360,"user":{"displayName":"Ethan Harvey","userId":"07419801998201839525"}},"outputId":"a391e5bd-ce9b-4903-b3f5-f94e30d8fa83"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"x8hmRhWzSEPj","executionInfo":{"status":"ok","timestamp":1669494385894,"user_tz":300,"elapsed":12,"user":{"displayName":"Ethan Harvey","userId":"07419801998201839525"}},"outputId":"14ad0179-1ba9-43c6-e03c-12c103be0250"},"outputs":[{"output_type":"display_data","data":{"application/javascript":["IPython.notebook.set_autosave_interval(180000)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Autosaving every 180 seconds\n"]}],"source":["# As usual, a bit of setup\n","import time\n","import numpy as np\n","import torch\n","import matplotlib.pyplot as plt\n","\n","\n","%matplotlib inline\n","plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n","plt.rcParams['image.interpolation'] = 'nearest'\n","plt.rcParams['image.cmap'] = 'gray'\n","\n","# for auto-reloading external modules\n","# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n","%load_ext autoreload\n","%autoreload 2\n","%autosave 180\n"]},{"cell_type":"code","source":["# If you have cuda, do the following\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MSz5wm6LLXDC","executionInfo":{"status":"ok","timestamp":1669494385896,"user_tz":300,"elapsed":10,"user":{"displayName":"Ethan Harvey","userId":"07419801998201839525"}},"outputId":"96117baf-f771-4e01-f359-1e254ed54d18"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}]},{"cell_type":"markdown","metadata":{"id":"pwzbS7PfSEPl"},"source":["## Load the data\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AkBF51HXSEPm","executionInfo":{"status":"ok","timestamp":1669494393879,"user_tz":300,"elapsed":6990,"user":{"displayName":"Ethan Harvey","userId":"07419801998201839525"}},"outputId":"d37cac41-b962-4955-c0b8-3c7fdc2684af"},"outputs":[{"output_type":"stream","name":"stdout","text":["The total of  4328 non-ascii chars are removed \n","\n","Data statistics:\n","Number of sentences:  160000\n","Maximum and minimum sentence lengths: 100 32\n","Total number of characters: 10954565\n","Vocabulary size:  95\n","Chars in vocabulary and their frequencies:\n","[('\\n', 160000), (' ', 1762678), ('!', 12100), ('#', 496), ('$', 1212), ('%', 450), ('&', 1366), (\"'\", 88729), ('(', 8734), (')', 8890), ('*', 4310), ('+', 123), (',', 33680), ('-', 20064), ('.', 108694), ('/', 1586), ('0', 11139), ('1', 10960), ('2', 7690), ('3', 3517), ('4', 2882), ('5', 4272), ('6', 2673), ('7', 2496), ('8', 2071), ('9', 2801), (':', 22223), (';', 607), ('<', 12), ('=', 103), ('>', 9), ('?', 48816), ('@', 34), ('A', 8259), ('B', 4063), ('C', 5317), ('D', 6787), ('E', 2239), ('F', 3232), ('G', 2668), ('H', 11482), ('I', 15839), ('J', 2999), ('K', 2315), ('L', 2612), ('M', 7724), ('N', 3017), ('O', 2211), ('P', 3722), ('Q', 1036), ('R', 2942), ('S', 7281), ('T', 15062), ('U', 1014), ('V', 720), ('W', 37161), ('X', 17), ('Y', 2381), ('Z', 149), ('[', 1), ('\\\\', 25), (']', 4), ('^', 322), ('_', 107), ('`', 16), ('a', 726754), ('b', 148176), ('c', 253811), ('d', 319199), ('e', 964237), ('f', 163468), ('g', 191416), ('h', 397259), ('i', 592936), ('j', 23898), ('k', 111404), ('l', 371704), ('m', 225041), ('n', 552588), ('o', 684697), ('p', 184115), ('q', 6356), ('r', 515062), ('s', 585280), ('t', 698276), ('u', 258476), ('v', 81822), ('w', 171901), ('x', 17369), ('y', 209349), ('z', 11610), ('{', 9), ('|', 66), ('}', 12), ('~', 133)]\n","Data exploration -- showing an example sentence:\n","Martha stewart tweets hideous food photo, twitter responds accordingly\n","\n"]}],"source":["import csv\n","import string\n","import numpy as np\n","\n","def load_data(data_file):\n","    \"\"\"Load the data into a list of strings\"\"\"\n","    \n","    with open('/content/drive/MyDrive/cs137assignments/assignment4/'+data_file) as csv_file:\n","        reader = csv.reader(csv_file, delimiter=',')\n","        rows = list(reader)\n","\n","    if data_file == 'train.csv':\n","        sentences, labels = zip(*rows[1:])\n","        sentences = list(sentences)\n","    elif data_file == 'test.csv':\n","        sentences = [row[0] for row in rows[1:]]\n","    else:\n","        print(\"Can only load 'train.csv' or 'test.csv'\")\n","    \n","    # replace non ascii chars to spaces\n","    count = 0\n","    for i, sen in enumerate(sentences):\n","        count = count + sum([0 if ord(i) < 128 else 1 for i in sen])\n","        \n","        # '\\n' indicates the end of the sentence\n","        sentences[i] = ''.join([i if ord(i) < 128 else ' ' for i in sen]) + '\\n'\n","        \n","    print('The total of ', count, 'non-ascii chars are removed \\n')\n","\n","    return sentences\n","\n","def char_to_index(sentence, str_voc):\n","    \"\"\"Convert a string to an array by using the index in the vocabulary\"\"\"\n","    \n","    sen_int = np.array([str_voc.index(c) for c in sentence])\n","    return sen_int\n","\n","def convert_sen_to_data(sentences, str_voc):\n","    \"\"\" Convert a list of strings to a list of numpy arrays\"\"\"\n","    data = [None] * len(sentences)\n","    for i, sen in enumerate(sentences):\n","        data[i] = char_to_index(sen, str_voc)\n","        \n","        # sanity check\n","        #if i < 5:\n","        #    recover = \"\".join([str_voc[k] for k in data[i]])\n","        #    print(recover)\n","    return data\n","\n","train_sentences = load_data('train.csv')\n","\n","# NOTE: you need to use the same vocabulary to handle your test sentences\n","vocabulary = list(set(\"\".join(train_sentences))) \n","vocabulary.sort()\n","str_voc = \"\".join(vocabulary)\n","\n","train_data = convert_sen_to_data(train_sentences, str_voc)\n","\n","\n","num_sen = len(train_data)\n","sen_lengths = [sen.shape[0] for sen in train_data]\n","max_len = max(sen_lengths)\n","min_len = min(sen_lengths)\n","num_chars = sum(sen_lengths)\n","\n","print('Data statistics:')\n","print('Number of sentences: ', num_sen)\n","print('Maximum and minimum sentence lengths:', max_len, min_len)\n","print('Total number of characters:', num_chars)\n","print('Vocabulary size: ', len(vocabulary))\n","\n","uniq, uniq_counts = np.unique(np.concatenate(train_data), return_counts=True)\n","freq = np.zeros_like(uniq_counts)\n","freq[uniq] = uniq_counts\n","\n","print('Chars in vocabulary and their frequencies:')\n","print(list(zip(vocabulary, freq.tolist())))\n","\n","\n","# a sample sentence\n","print(\"Data exploration -- showing an example sentence:\")\n","\n","sample = \"\"\n","for i in train_data[5]:\n","    sample +=str_voc[i] \n","print(sample)\n"]},{"cell_type":"markdown","metadata":{"id":"3QAVAQAHSEPn"},"source":["## Implement an RNN or a Transformer with torch\n","\n","**Q7 (10 points)** In this problem, you are supposed to train an RNN or a transformer to model sentences. Particuarly, your model will receive 10 starting characters and should predict the rest of sentence. The model will be evaluated by per-character cross-entropy loss. You will get \n","* 5 points if your per-character cross-entropy loss is less than 2.5 (the loss by predicting with character frequencies is 3.13. Your model needs to be better than that). \n","* 8 points if your per-character cross-entropy loss is less than 2\n","* 10 points if your per-character cross-entropy loss is less than 1.5\n","\n","\\*The performance from a [paper](https://arxiv.org/pdf/1808.04444.pdf) indicates that an LSTM can achieve performance of 1.43 * ln(2) = 0.991. \n","\\*The `zip` program for compressing files roughly can achieve a performances of 3.522 bits per character. It corresponds to a performance of  3.522 * ln(2) = 2.441"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"_O_MvBICSEPo","executionInfo":{"status":"ok","timestamp":1669494393880,"user_tz":300,"elapsed":13,"user":{"displayName":"Ethan Harvey","userId":"07419801998201839525"}}},"outputs":[],"source":["# Set up dataloader\n","\n","# TODO: please read through the code in this cell so you know the data your model will see. \n","\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn.utils.rnn import pad_sequence\n","\n","\n","class StrData(Dataset):\n","    def __init__(self, data):\n","        self.sentence = data\n","    def __len__(self):\n","        return len(self.sentence)\n","    def __getitem__(self, idx):\n","        return self.sentence[idx]\n","\n","BEGIN_ID = freq.shape[0]\n","END_ID = BEGIN_ID + 1\n","PAD_ID = BEGIN_ID + 2\n","\n","def add_begin_and_end(tokens):\n","    return torch.cat([torch.tensor([BEGIN_ID], dtype = torch.long),\n","                     torch.tensor(tokens, dtype = torch.long),\n","                     torch.tensor([END_ID], dtype = torch.long)])\n","\n","def collate_fn(batch):\n","    batch_ret = []\n","    for sentence in batch:\n","        batch_ret.append(add_begin_and_end(sentence))\n","    batch_ret = pad_sequence(batch_ret, padding_value = PAD_ID).T # pad_sequence is not batch_first\n","    return batch_ret\n","\n"]},{"cell_type":"markdown","metadata":{"id":"zBkup_9kSEPo"},"source":["### Set up a model\n","\n","Suggestion: you may want to put your model in a `.py` file. Your code might look cleaner if you do so."]},{"cell_type":"code","execution_count":10,"metadata":{"id":"JARprTNkSEPp","executionInfo":{"status":"ok","timestamp":1669494433969,"user_tz":300,"elapsed":6854,"user":{"displayName":"Ethan Harvey","userId":"07419801998201839525"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"68537776-02e7-41c5-a3ea-12b67bd44860"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["SentenceModel(\n","  (emb): Embedding(98, 256)\n","  (rnn): RNN(256, 1000, batch_first=True)\n","  (linear): Linear(in_features=1000, out_features=98, bias=True)\n",")"]},"metadata":{},"execution_count":10}],"source":["from rnn_lm import SentenceModel\n","\n","model = SentenceModel(freq)\n","model.to(device)"]},{"cell_type":"markdown","metadata":{"id":"tvVRLjvpSEPq"},"source":["### Train the model\n","\n","NOTE: this example only uses 20 sentences for fast showcase the code, but you should use the entire training set. You can also split out a subset as the validation set. You can make any changes as long as you don't touch the test set.   "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zGYwb2npSEPq","executionInfo":{"status":"ok","timestamp":1669489036161,"user_tz":300,"elapsed":305702,"user":{"displayName":"Ethan Harvey","userId":"07419801998201839525"}},"outputId":"cf16d500-ded9-43d6-e366-bbe55f2f7cc9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5: Training Loss 1.598863556098938\n","Epoch 2/5: Training Loss 1.410946901845932\n","Epoch 3/5: Training Loss 1.372951064491272\n","Epoch 4/5: Training Loss 1.3548198021888733\n","Epoch 5/5: Training Loss 1.3454062554836272\n"]}],"source":["epochs = 5\n","\n","train_loader = DataLoader(StrData(train_data), shuffle=True, batch_size=64, collate_fn=collate_fn)\n","\n","opt = torch.optim.Adam(model.parameters(), lr=0.001)\n","loss_fn = torch.nn.CrossEntropyLoss(ignore_index = PAD_ID)\n","for ep in range(epochs):\n","    running_loss = 0\n","    for i, batch in enumerate(train_loader):\n","\n","        m_input = batch[:, :-1] \n","        m_output = batch[:, 1:]\n","\n","        if device.type == \"cuda\":\n","            m_input = m_input.to(device)\n","            m_output = m_output.to(device)\n","        \n","         # zero the parameter gradients\n","        opt.zero_grad()\n","        \n","        logits = model(m_input) # batch x no_sequences x logits\n","        # Question: is this teacher forcing? \n","        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), m_output.reshape(-1)) # * x vocab_size, * \n","        loss.backward()\n","        \n","        opt.step()\n","\n","        # TODO: Record loss values to some variable\n","        if device.type == \"cuda\":\n","            loss = loss.cpu()\n","\n","        running_loss += loss.item()\n","    print(f\"Epoch {ep+1}/{epochs}: Training Loss {running_loss / (i+1)}\")"]},{"cell_type":"markdown","metadata":{"id":"x2gH37WLSEPr"},"source":["### Save the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f7ibm6IVSEPr"},"outputs":[],"source":["torch.save(model, \"rnn_lm.sav\")"]},{"cell_type":"markdown","metadata":{"id":"CFBISn7iSEPr"},"source":["### Test the trained model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n8zvK_a8SEPs","executionInfo":{"status":"ok","timestamp":1669489072078,"user_tz":300,"elapsed":8350,"user":{"displayName":"Ethan Harvey","userId":"07419801998201839525"}},"outputId":"8c4e1f27-fed4-4f64-fd63-adeb7b865eba"},"outputs":[{"output_type":"stream","name":"stdout","text":["The total of  1131 non-ascii chars are removed \n","\n","Number of test instances: 40000\n","Evaluating the model ...\n","The total number of chars in the test set is  tensor(2739550, device='cuda:0')\n","The per-char-loss is 1.363\n"]}],"source":["\n","# load the test data. NOTE: need to use the same vocabulary as the training data\n","test_sentences = load_data('test.csv')\n","test_data = convert_sen_to_data(test_sentences, str_voc)\n","\n","\n","print('Number of test instances:', len(test_data))\n","\n","# TODO: replace this stub model with your powerful model\n","model = torch.load(\"rnn_lm.sav\")\n","\n","test_loader = DataLoader(StrData(test_data), shuffle=True, batch_size=50, collate_fn=collate_fn)\n","loss_fn = torch.nn.CrossEntropyLoss(ignore_index = PAD_ID)\n","print('Evaluating the model ...')\n","loss_sum = 0\n","char_count = 0\n","with torch.no_grad():\n","    for i, batch in enumerate(test_loader):\n","        m_input = batch[:, :-1]\n","        m_output = batch[:, 1:]\n","\n","        if device.type == \"cuda\":\n","            m_input = m_input.to(device)\n","            m_output = m_output.to(device)\n","    \n","        logits = model(m_input)\n","        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), m_output.reshape(-1))\n","\n","        if device.type == \"cuda\":\n","            loss = loss.to(device)\n","            batch = batch.to(device)\n","\n","        loss_sum += loss.item()\n","        char_count += torch.sum((batch != PAD_ID) & (batch != BEGIN_ID) & (batch != END_ID))\n","        \n","per_char_loss = loss_sum / (i+1)\n","\n","print('The total number of chars in the test set is ', char_count)\n","\n","print('The per-char-loss is %.3f' % per_char_loss)\n"]},{"cell_type":"markdown","metadata":{"id":"Sl7VJ2VsSEPs"},"source":["### Use the model to generate sentences\n","\n","Now we can use the trained model to generate text with a starting string. The naive model just predict frequent characters in the text, so there is no meaningful generation yet. See what you get from your models."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s1499lDlSEPs","executionInfo":{"status":"ok","timestamp":1669489432676,"user_tz":300,"elapsed":850,"user":{"displayName":"Ethan Harvey","userId":"07419801998201839525"}},"outputId":"febb15ce-f12f-4f9c-cd65-3eef397a12e4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Starting from \"I hav\", the generated sentence is:\n","\"I haven test (photos)\"\n"]}],"source":["import torch.distributions as distributions\n","\n","def generate_text(model, start_string, str_voc):\n","    \"\"\" Generate random text from a starting string. \"\"\"\n","\n","    # Number of characters to generate\n","    num_generate = 100 - len(start_string)\n","\n","    # Converting our start string to numbers (vectorizing)\n","    input_int = [BEGIN_ID] + [str_voc.index(s) for s in start_string]\n","    input_tensor = torch.tensor(input_int, dtype = torch.long).view([1, -1])\n","    \n","    # Empty string to store our results\n","    text_generated = []\n","\n","    # Low temperature results in more predictable text.\n","    # Higher temperature results in more surprising text.\n","    # Experiment to find the best setting.\n","    temperature = 0.5\n","    \n","    # Here batch size == 1\n","    other_voc = {BEGIN_ID: \"<BEG>\", END_ID: \"<END>\", PAD_ID: \"<PAD>\"}\n","    \n","    for i in range(num_generate):\n","\n","        if device.type == \"cuda\":\n","            input_tensor = input_tensor.to(device)\n","        \n","        outputs = model(input_tensor)\n","        \n","        # remove the batch dimension\n","        prediction = torch.softmax(outputs[0, -1, :], dim=0)\n","\n","        # using a categorical distribution to predict the character returned by the model\n","        prediction = prediction / temperature\n","        predicted_id = int(distributions.Categorical(probs = prediction).sample())\n","\n","        \n","        # The calculation has a lot of repeatition because computation for the first part \n","        # of the sequence is the same at every iteration. But it's fine for our example.\n","        input_int.append(predicted_id)\n","        input_tensor = torch.tensor(input_int, dtype = torch.long).view([1, -1])\n","\n","        \n","        text_generated.append(str_voc[predicted_id] if (predicted_id < len(str_voc)) else other_voc[predicted_id])\n","\n","    return (start_string + ''.join(text_generated))\n","\n","\n","start_string = 'I hav'\n","gen_sen = generate_text(model, start_string, str_voc)\n","gen_sen = gen_sen.split('\\n')[0]\n","\n","print('Starting from \"' + start_string + '\", the generated sentence is:')\n","print('\"' + gen_sen + '\"')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8s2BLMSYSEPt"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}